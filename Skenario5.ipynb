{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skenario5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZVoPi8tE06rUah9DIaEK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpdab/tugasscdl/blob/main/skenario5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYswe8t8mTQs",
        "outputId": "f544e78a-a294-4c15-f779-fee55906c99c"
      },
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssyDt-UmnXZ3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S7L-Cqplna44",
        "outputId": "b21821f5-ebde-44af-9f18-8e1c8f600105"
      },
      "source": [
        "#memakai dataset\n",
        "URL = 'https://raw.githubusercontent.com/martinpdab/tugasscdl/main/data%20fix.csv' \n",
        "dataframe = pd.read_csv(URL)\n",
        "dataframe"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Period</th>\n",
              "      <th>TE</th>\n",
              "      <th>HU</th>\n",
              "      <th>RF</th>\n",
              "      <th>WS</th>\n",
              "      <th>PD</th>\n",
              "      <th>ABJ</th>\n",
              "      <th>LAG0</th>\n",
              "      <th>LAG1</th>\n",
              "      <th>LAG2</th>\n",
              "      <th>LAG3</th>\n",
              "      <th>LAG4</th>\n",
              "      <th>LAG5</th>\n",
              "      <th>LAG6</th>\n",
              "      <th>LAG7</th>\n",
              "      <th>LAG8</th>\n",
              "      <th>LAG9</th>\n",
              "      <th>LAG10</th>\n",
              "      <th>LAG11</th>\n",
              "      <th>LAG12</th>\n",
              "      <th>OS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jan-10</td>\n",
              "      <td>26.02</td>\n",
              "      <td>84.74</td>\n",
              "      <td>10.52</td>\n",
              "      <td>0.84</td>\n",
              "      <td>792.86</td>\n",
              "      <td>86.96</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Feb-10</td>\n",
              "      <td>26.32</td>\n",
              "      <td>84.64</td>\n",
              "      <td>12.04</td>\n",
              "      <td>0.86</td>\n",
              "      <td>793.45</td>\n",
              "      <td>86.72</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mar-10</td>\n",
              "      <td>26.39</td>\n",
              "      <td>85.00</td>\n",
              "      <td>8.65</td>\n",
              "      <td>0.55</td>\n",
              "      <td>794.04</td>\n",
              "      <td>86.50</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apr-10</td>\n",
              "      <td>26.29</td>\n",
              "      <td>86.17</td>\n",
              "      <td>10.37</td>\n",
              "      <td>0.30</td>\n",
              "      <td>794.63</td>\n",
              "      <td>86.28</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>May-10</td>\n",
              "      <td>26.57</td>\n",
              "      <td>85.61</td>\n",
              "      <td>7.35</td>\n",
              "      <td>0.58</td>\n",
              "      <td>795.22</td>\n",
              "      <td>86.08</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>Aug-18</td>\n",
              "      <td>24.27</td>\n",
              "      <td>76.87</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.39</td>\n",
              "      <td>846.18</td>\n",
              "      <td>96.29</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>Sep-18</td>\n",
              "      <td>25.50</td>\n",
              "      <td>75.73</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.03</td>\n",
              "      <td>846.59</td>\n",
              "      <td>93.34</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>Oct-18</td>\n",
              "      <td>26.58</td>\n",
              "      <td>74.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.39</td>\n",
              "      <td>847.01</td>\n",
              "      <td>96.10</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>Nov-18</td>\n",
              "      <td>26.49</td>\n",
              "      <td>82.28</td>\n",
              "      <td>10.53</td>\n",
              "      <td>1.00</td>\n",
              "      <td>847.42</td>\n",
              "      <td>96.38</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>Dec-18</td>\n",
              "      <td>26.14</td>\n",
              "      <td>85.45</td>\n",
              "      <td>10.41</td>\n",
              "      <td>0.87</td>\n",
              "      <td>847.84</td>\n",
              "      <td>95.35</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Period     TE     HU     RF    WS  ...  LAG9  LAG10  LAG11  LAG12  OS\n",
              "0    Jan-10  26.02  84.74  10.52  0.84  ...     5      2      1      4   0\n",
              "1    Feb-10  26.32  84.64  12.04  0.86  ...     3      5      2      1   1\n",
              "2    Mar-10  26.39  85.00   8.65  0.55  ...     3      3      5      2   0\n",
              "3    Apr-10  26.29  86.17  10.37  0.30  ...     4      3      3      5   0\n",
              "4    May-10  26.57  85.61   7.35  0.58  ...     1      4      3      3   0\n",
              "..      ...    ...    ...    ...   ...  ...   ...    ...    ...    ...  ..\n",
              "103  Aug-18  24.27  76.87   0.00  1.39  ...     1      1      2      3   0\n",
              "104  Sep-18  25.50  75.73   0.59  1.03  ...     1      1      1      2   1\n",
              "105  Oct-18  26.58  74.94   0.04  1.39  ...     4      1      1      1   1\n",
              "106  Nov-18  26.49  82.28  10.53  1.00  ...     1      4      1      1   1\n",
              "107  Dec-18  26.14  85.45  10.41  0.87  ...     2      1      4      1   1\n",
              "\n",
              "[108 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4brS07ETG9Jm",
        "outputId": "4f0a5074-5fc2-470d-f8a2-1245b6278adf"
      },
      "source": [
        "#mengambil kolom period, rf, dan os serta mengacak dataset\n",
        "data = dataframe[['RF', 'OS']]\n",
        "data = shuffle(data)\n",
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RF</th>\n",
              "      <th>OS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>15.03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>3.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>6.59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>13.48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       RF  OS\n",
              "36  15.03   0\n",
              "68   0.00   0\n",
              "64   3.53   0\n",
              "79   6.59   0\n",
              "76  13.48   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8oxWDe3DhTz",
        "outputId": "1e1f8b35-c018-4948-d574-e1387eb1aae3"
      },
      "source": [
        "data.describe()\n",
        "data.isnull().sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RF    0\n",
              "OS    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8ZB5NduI9sN",
        "outputId": "5ddd4a6d-8813-4392-af2c-c1d4959819f9"
      },
      "source": [
        "#Splitting data into feature and label\n",
        "x = data.drop(\"OS\", 1)\n",
        "y = data[\"OS\"]\n",
        "\n",
        "#train-test split 80-20\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "print(len(x_train), 'banyak data train')\n",
        "print(len(x_test), 'banyak data test')\n",
        "\n",
        "#train-test split 70-30\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(x, y, test_size = 0.3)\n",
        "print(len(x_train1), 'banyak data train')\n",
        "print(len(x_test1), 'banyak data test')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86 banyak data train\n",
            "22 banyak data test\n",
            "75 banyak data train\n",
            "33 banyak data test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "IYnAFQsIKECO",
        "outputId": "bd773af8-d927-403c-d718-7900ada75ccf"
      },
      "source": [
        "f = plt.figure(figsize=(12,4))\n",
        "f.add_subplot(1,2,1)\n",
        "sns.countplot(data['RF'])\n",
        "f.add_subplot(1,2,2)\n",
        "plt.boxplot(data['RF'])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MlC89IB1M7Jj",
        "outputId": "2f2370c8-76ab-4758-ed32-5c8e8bbbae2e"
      },
      "source": [
        "plt.scatter(data['RF'], data['OS'])\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g355mS9UNf2k"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(512, activation='relu'),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation='relu'),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFrZdTjaETdv",
        "outputId": "68ae29f8-cd57-4b19-cffa-c9b76b45d261"
      },
      "source": [
        "history=model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=10, verbose=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5205 - accuracy: 0.7791 - val_loss: 0.7532 - val_accuracy: 0.5909\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5398 - accuracy: 0.7674 - val_loss: 0.7478 - val_accuracy: 0.5909\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5429 - accuracy: 0.7674 - val_loss: 0.7515 - val_accuracy: 0.5909\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7674 - val_loss: 0.7576 - val_accuracy: 0.5909\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7558 - val_loss: 0.7692 - val_accuracy: 0.5909\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.7674 - val_loss: 0.7720 - val_accuracy: 0.5909\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5404 - accuracy: 0.7791 - val_loss: 0.7687 - val_accuracy: 0.5909\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5397 - accuracy: 0.7674 - val_loss: 0.7683 - val_accuracy: 0.5909\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7674 - val_loss: 0.7643 - val_accuracy: 0.5909\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.7674 - val_loss: 0.7683 - val_accuracy: 0.5909\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5592 - accuracy: 0.7674 - val_loss: 0.7713 - val_accuracy: 0.5909\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7674 - val_loss: 0.7708 - val_accuracy: 0.5909\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7674 - val_loss: 0.7699 - val_accuracy: 0.5909\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7791 - val_loss: 0.7701 - val_accuracy: 0.5909\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7674 - val_loss: 0.7599 - val_accuracy: 0.5909\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5392 - accuracy: 0.7791 - val_loss: 0.7470 - val_accuracy: 0.5909\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.7674 - val_loss: 0.7439 - val_accuracy: 0.5909\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.7674 - val_loss: 0.7481 - val_accuracy: 0.5909\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5564 - accuracy: 0.7558 - val_loss: 0.7613 - val_accuracy: 0.5909\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5505 - accuracy: 0.7674 - val_loss: 0.7565 - val_accuracy: 0.5909\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5402 - accuracy: 0.7674 - val_loss: 0.7531 - val_accuracy: 0.5909\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7674 - val_loss: 0.7608 - val_accuracy: 0.5909\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7674 - val_loss: 0.7750 - val_accuracy: 0.5909\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7674 - val_loss: 0.7772 - val_accuracy: 0.5909\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.7674 - val_loss: 0.7750 - val_accuracy: 0.5909\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5520 - accuracy: 0.7674 - val_loss: 0.7716 - val_accuracy: 0.5909\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.7674 - val_loss: 0.7630 - val_accuracy: 0.5909\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7674 - val_loss: 0.7651 - val_accuracy: 0.5909\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7674 - val_loss: 0.7638 - val_accuracy: 0.5909\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7674 - val_loss: 0.7626 - val_accuracy: 0.5909\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7674 - val_loss: 0.7560 - val_accuracy: 0.5909\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7674 - val_loss: 0.7496 - val_accuracy: 0.5909\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7791 - val_loss: 0.7513 - val_accuracy: 0.5909\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5387 - accuracy: 0.7791 - val_loss: 0.7551 - val_accuracy: 0.5909\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7674 - val_loss: 0.7565 - val_accuracy: 0.5909\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.7674 - val_loss: 0.7724 - val_accuracy: 0.5909\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7674 - val_loss: 0.7684 - val_accuracy: 0.5909\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7674 - val_loss: 0.7695 - val_accuracy: 0.5909\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5276 - accuracy: 0.7674 - val_loss: 0.7713 - val_accuracy: 0.5909\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7674 - val_loss: 0.7646 - val_accuracy: 0.5909\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5458 - accuracy: 0.7674 - val_loss: 0.7541 - val_accuracy: 0.5909\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5419 - accuracy: 0.7674 - val_loss: 0.7623 - val_accuracy: 0.5909\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5470 - accuracy: 0.7558 - val_loss: 0.7623 - val_accuracy: 0.5909\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5568 - accuracy: 0.7674 - val_loss: 0.7613 - val_accuracy: 0.5909\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5608 - accuracy: 0.7674 - val_loss: 0.7678 - val_accuracy: 0.5909\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7674 - val_loss: 0.7698 - val_accuracy: 0.5909\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5390 - accuracy: 0.7674 - val_loss: 0.7764 - val_accuracy: 0.5909\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5383 - accuracy: 0.7674 - val_loss: 0.7710 - val_accuracy: 0.5909\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7674 - val_loss: 0.7600 - val_accuracy: 0.5909\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7674 - val_loss: 0.7662 - val_accuracy: 0.5909\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7674 - val_loss: 0.7699 - val_accuracy: 0.5909\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7674 - val_loss: 0.7705 - val_accuracy: 0.5909\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5284 - accuracy: 0.7674 - val_loss: 0.7678 - val_accuracy: 0.5909\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5414 - accuracy: 0.7674 - val_loss: 0.7734 - val_accuracy: 0.5909\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.7674 - val_loss: 0.7684 - val_accuracy: 0.5909\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7558 - val_loss: 0.7673 - val_accuracy: 0.5909\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5448 - accuracy: 0.7674 - val_loss: 0.7785 - val_accuracy: 0.5909\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5419 - accuracy: 0.7674 - val_loss: 0.7853 - val_accuracy: 0.5909\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7674 - val_loss: 0.7785 - val_accuracy: 0.5909\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7674 - val_loss: 0.7649 - val_accuracy: 0.5909\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7674 - val_loss: 0.7698 - val_accuracy: 0.5909\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7674 - val_loss: 0.7774 - val_accuracy: 0.5909\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.7674 - val_loss: 0.7813 - val_accuracy: 0.5909\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5449 - accuracy: 0.7674 - val_loss: 0.7829 - val_accuracy: 0.5909\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5537 - accuracy: 0.7674 - val_loss: 0.7778 - val_accuracy: 0.5909\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7674 - val_loss: 0.7759 - val_accuracy: 0.5909\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7674 - val_loss: 0.7772 - val_accuracy: 0.5909\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5589 - accuracy: 0.7674 - val_loss: 0.7704 - val_accuracy: 0.5909\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5367 - accuracy: 0.7674 - val_loss: 0.7697 - val_accuracy: 0.5909\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.7674 - val_loss: 0.7706 - val_accuracy: 0.5909\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7674 - val_loss: 0.7648 - val_accuracy: 0.5909\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7674 - val_loss: 0.7674 - val_accuracy: 0.5909\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5370 - accuracy: 0.7674 - val_loss: 0.7637 - val_accuracy: 0.5909\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5539 - accuracy: 0.7558 - val_loss: 0.7628 - val_accuracy: 0.5909\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5344 - accuracy: 0.7674 - val_loss: 0.7634 - val_accuracy: 0.5909\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7674 - val_loss: 0.7758 - val_accuracy: 0.5909\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7674 - val_loss: 0.7714 - val_accuracy: 0.5909\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.7674 - val_loss: 0.7658 - val_accuracy: 0.5909\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5278 - accuracy: 0.7674 - val_loss: 0.7609 - val_accuracy: 0.5909\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7674 - val_loss: 0.7695 - val_accuracy: 0.5909\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7674 - val_loss: 0.7748 - val_accuracy: 0.5909\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7791 - val_loss: 0.7679 - val_accuracy: 0.5909\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5667 - accuracy: 0.7558 - val_loss: 0.7649 - val_accuracy: 0.5909\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7674 - val_loss: 0.7796 - val_accuracy: 0.5909\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5485 - accuracy: 0.7674 - val_loss: 0.7645 - val_accuracy: 0.5909\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5340 - accuracy: 0.7674 - val_loss: 0.7651 - val_accuracy: 0.5909\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7674 - val_loss: 0.7577 - val_accuracy: 0.5909\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5443 - accuracy: 0.7674 - val_loss: 0.7632 - val_accuracy: 0.5909\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7674 - val_loss: 0.7623 - val_accuracy: 0.5909\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5518 - accuracy: 0.7558 - val_loss: 0.7689 - val_accuracy: 0.5909\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7674 - val_loss: 0.7775 - val_accuracy: 0.5909\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5215 - accuracy: 0.7674 - val_loss: 0.7738 - val_accuracy: 0.5909\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5392 - accuracy: 0.7791 - val_loss: 0.7759 - val_accuracy: 0.5909\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5157 - accuracy: 0.7791 - val_loss: 0.7762 - val_accuracy: 0.5909\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5578 - accuracy: 0.7674 - val_loss: 0.7803 - val_accuracy: 0.5909\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5501 - accuracy: 0.7674 - val_loss: 0.7772 - val_accuracy: 0.5909\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5308 - accuracy: 0.7674 - val_loss: 0.7714 - val_accuracy: 0.5909\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5502 - accuracy: 0.7674 - val_loss: 0.7753 - val_accuracy: 0.5909\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7674 - val_loss: 0.7768 - val_accuracy: 0.5909\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5466 - accuracy: 0.7674 - val_loss: 0.7811 - val_accuracy: 0.5909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X421dxwRGFQc",
        "outputId": "180ee466-0a36-4c7e-8dcc-0212e94763cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history1=model.fit(x_train1, y_train1, validation_data=(x_test1, y_test1), epochs=100, batch_size=10, verbose=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6086 - accuracy: 0.6933 - val_loss: 0.5037 - val_accuracy: 0.8182\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6126 - accuracy: 0.7067 - val_loss: 0.5017 - val_accuracy: 0.8182\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6053 - accuracy: 0.7067 - val_loss: 0.5025 - val_accuracy: 0.8182\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6061 - accuracy: 0.6933 - val_loss: 0.4994 - val_accuracy: 0.8182\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6933 - val_loss: 0.5001 - val_accuracy: 0.8182\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5993 - accuracy: 0.6933 - val_loss: 0.4971 - val_accuracy: 0.8182\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6300 - accuracy: 0.6933 - val_loss: 0.4994 - val_accuracy: 0.8182\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6033 - accuracy: 0.6933 - val_loss: 0.4996 - val_accuracy: 0.8182\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6256 - accuracy: 0.6933 - val_loss: 0.4997 - val_accuracy: 0.8182\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6218 - accuracy: 0.6933 - val_loss: 0.5007 - val_accuracy: 0.8182\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6180 - accuracy: 0.6933 - val_loss: 0.4997 - val_accuracy: 0.8182\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6179 - accuracy: 0.6933 - val_loss: 0.5025 - val_accuracy: 0.8182\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6092 - accuracy: 0.6933 - val_loss: 0.5021 - val_accuracy: 0.8182\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6164 - accuracy: 0.6933 - val_loss: 0.5039 - val_accuracy: 0.8182\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6071 - accuracy: 0.6933 - val_loss: 0.5042 - val_accuracy: 0.8182\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6046 - accuracy: 0.6933 - val_loss: 0.5059 - val_accuracy: 0.8182\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6349 - accuracy: 0.6933 - val_loss: 0.5072 - val_accuracy: 0.8182\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6210 - accuracy: 0.6933 - val_loss: 0.5048 - val_accuracy: 0.8182\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6100 - accuracy: 0.6933 - val_loss: 0.5049 - val_accuracy: 0.8182\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6150 - accuracy: 0.6933 - val_loss: 0.5061 - val_accuracy: 0.8182\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6026 - accuracy: 0.6933 - val_loss: 0.5075 - val_accuracy: 0.8182\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6128 - accuracy: 0.6933 - val_loss: 0.5072 - val_accuracy: 0.8182\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6175 - accuracy: 0.6933 - val_loss: 0.5069 - val_accuracy: 0.8182\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6253 - accuracy: 0.6933 - val_loss: 0.5062 - val_accuracy: 0.8182\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6263 - accuracy: 0.6933 - val_loss: 0.5095 - val_accuracy: 0.8182\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6206 - accuracy: 0.6933 - val_loss: 0.5095 - val_accuracy: 0.8182\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.6933 - val_loss: 0.5104 - val_accuracy: 0.8182\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6130 - accuracy: 0.6933 - val_loss: 0.5085 - val_accuracy: 0.8182\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.6933 - val_loss: 0.5089 - val_accuracy: 0.8182\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6295 - accuracy: 0.6933 - val_loss: 0.5086 - val_accuracy: 0.8182\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6115 - accuracy: 0.6933 - val_loss: 0.5096 - val_accuracy: 0.8182\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6246 - accuracy: 0.6933 - val_loss: 0.5092 - val_accuracy: 0.8182\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6094 - accuracy: 0.6933 - val_loss: 0.5119 - val_accuracy: 0.8182\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.6933 - val_loss: 0.5111 - val_accuracy: 0.8182\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6054 - accuracy: 0.7067 - val_loss: 0.5102 - val_accuracy: 0.8182\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.6933 - val_loss: 0.5071 - val_accuracy: 0.8182\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6182 - accuracy: 0.6933 - val_loss: 0.5098 - val_accuracy: 0.8182\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6155 - accuracy: 0.6800 - val_loss: 0.5133 - val_accuracy: 0.8182\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6155 - accuracy: 0.6933 - val_loss: 0.5114 - val_accuracy: 0.8182\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6102 - accuracy: 0.6933 - val_loss: 0.5115 - val_accuracy: 0.8182\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6151 - accuracy: 0.6933 - val_loss: 0.5108 - val_accuracy: 0.8182\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6253 - accuracy: 0.6933 - val_loss: 0.5093 - val_accuracy: 0.8182\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6046 - accuracy: 0.6933 - val_loss: 0.5088 - val_accuracy: 0.8182\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6140 - accuracy: 0.6933 - val_loss: 0.5069 - val_accuracy: 0.8182\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6113 - accuracy: 0.6933 - val_loss: 0.5065 - val_accuracy: 0.8182\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6038 - accuracy: 0.6933 - val_loss: 0.5058 - val_accuracy: 0.8182\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6095 - accuracy: 0.6933 - val_loss: 0.5059 - val_accuracy: 0.8182\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6166 - accuracy: 0.6933 - val_loss: 0.5050 - val_accuracy: 0.8182\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6047 - accuracy: 0.6933 - val_loss: 0.5052 - val_accuracy: 0.8182\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6300 - accuracy: 0.6933 - val_loss: 0.5049 - val_accuracy: 0.8182\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6229 - accuracy: 0.6933 - val_loss: 0.5072 - val_accuracy: 0.8182\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.6933 - val_loss: 0.5077 - val_accuracy: 0.8182\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6253 - accuracy: 0.6933 - val_loss: 0.5069 - val_accuracy: 0.8182\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6063 - accuracy: 0.6933 - val_loss: 0.5062 - val_accuracy: 0.8182\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6200 - accuracy: 0.6933 - val_loss: 0.5053 - val_accuracy: 0.8182\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6149 - accuracy: 0.6933 - val_loss: 0.5062 - val_accuracy: 0.8182\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6210 - accuracy: 0.6933 - val_loss: 0.5056 - val_accuracy: 0.8182\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6153 - accuracy: 0.6933 - val_loss: 0.5059 - val_accuracy: 0.8182\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6305 - accuracy: 0.6933 - val_loss: 0.5050 - val_accuracy: 0.8182\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6059 - accuracy: 0.6933 - val_loss: 0.5064 - val_accuracy: 0.8182\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.6933 - val_loss: 0.5049 - val_accuracy: 0.8182\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6112 - accuracy: 0.6933 - val_loss: 0.5027 - val_accuracy: 0.8182\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6252 - accuracy: 0.6933 - val_loss: 0.5054 - val_accuracy: 0.8182\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6127 - accuracy: 0.6933 - val_loss: 0.5060 - val_accuracy: 0.8182\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6324 - accuracy: 0.6933 - val_loss: 0.5107 - val_accuracy: 0.8182\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6277 - accuracy: 0.6933 - val_loss: 0.5116 - val_accuracy: 0.8182\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6251 - accuracy: 0.6933 - val_loss: 0.5149 - val_accuracy: 0.8182\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6165 - accuracy: 0.6933 - val_loss: 0.5166 - val_accuracy: 0.8182\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6212 - accuracy: 0.6933 - val_loss: 0.5159 - val_accuracy: 0.8182\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6232 - accuracy: 0.6933 - val_loss: 0.5155 - val_accuracy: 0.8182\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6137 - accuracy: 0.6933 - val_loss: 0.5139 - val_accuracy: 0.8182\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6185 - accuracy: 0.6933 - val_loss: 0.5116 - val_accuracy: 0.8182\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6147 - accuracy: 0.6933 - val_loss: 0.5124 - val_accuracy: 0.8182\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6235 - accuracy: 0.6933 - val_loss: 0.5130 - val_accuracy: 0.8182\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6154 - accuracy: 0.6933 - val_loss: 0.5119 - val_accuracy: 0.8182\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6196 - accuracy: 0.6933 - val_loss: 0.5108 - val_accuracy: 0.8182\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6259 - accuracy: 0.6933 - val_loss: 0.5092 - val_accuracy: 0.8182\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6164 - accuracy: 0.6933 - val_loss: 0.5096 - val_accuracy: 0.8182\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6172 - accuracy: 0.6933 - val_loss: 0.5093 - val_accuracy: 0.8182\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6119 - accuracy: 0.6933 - val_loss: 0.5110 - val_accuracy: 0.8182\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6122 - accuracy: 0.6933 - val_loss: 0.5085 - val_accuracy: 0.8182\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6109 - accuracy: 0.6933 - val_loss: 0.5071 - val_accuracy: 0.8182\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6121 - accuracy: 0.6933 - val_loss: 0.5047 - val_accuracy: 0.8182\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6131 - accuracy: 0.6933 - val_loss: 0.5067 - val_accuracy: 0.8182\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6056 - accuracy: 0.6933 - val_loss: 0.5046 - val_accuracy: 0.8182\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6106 - accuracy: 0.6933 - val_loss: 0.5041 - val_accuracy: 0.8182\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6100 - accuracy: 0.6933 - val_loss: 0.5034 - val_accuracy: 0.8182\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6279 - accuracy: 0.6933 - val_loss: 0.5055 - val_accuracy: 0.8182\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6302 - accuracy: 0.6933 - val_loss: 0.5084 - val_accuracy: 0.8182\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6178 - accuracy: 0.6933 - val_loss: 0.5058 - val_accuracy: 0.8182\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6139 - accuracy: 0.6933 - val_loss: 0.5076 - val_accuracy: 0.8182\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6163 - accuracy: 0.6933 - val_loss: 0.5124 - val_accuracy: 0.8182\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.6128 - accuracy: 0.6933 - val_loss: 0.5171 - val_accuracy: 0.8182\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6135 - accuracy: 0.6933 - val_loss: 0.5162 - val_accuracy: 0.8182\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6164 - accuracy: 0.6933 - val_loss: 0.5162 - val_accuracy: 0.8182\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.6933 - val_loss: 0.5133 - val_accuracy: 0.8182\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6345 - accuracy: 0.6933 - val_loss: 0.5121 - val_accuracy: 0.8182\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 0.6933 - val_loss: 0.5119 - val_accuracy: 0.8182\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6143 - accuracy: 0.6933 - val_loss: 0.5153 - val_accuracy: 0.8182\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6247 - accuracy: 0.6933 - val_loss: 0.5153 - val_accuracy: 0.8182\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
